{"cells":[{"cell_type":"code","execution_count":24,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":0,"status":"ok","timestamp":1659747795054,"user":{"displayName":"ì„±ë¯¼ì œ","userId":"17141149487272394423"},"user_tz":-540},"id":"5RnTs8WpyyOW"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/yolov5\n"]}],"source":["\n","# !git clone https://github.com/ultralytics/yolov5\n","%cd /content/drive/MyDrive/yolov5\n","%pip install -qr requirements.txt\n","\n","import torch\n","from IPython.display import Image, clear_output"]},{"cell_type":"markdown","metadata":{"id":"Q8CleaAlOp19"},"source":["ëŒ€ìš©ëŸ‰ íŒŒì¼ì„ êµ¬ê¸€ë“œë¼ì´ë¸Œì— ì—…ë¡œë“œ í•œ ë’¤ ì½”ë©ì—ì„œ ë¶ˆëŸ¬ì˜¤ë©´ \n","ë¶ˆëŸ¬ì˜¤ëŠ” ê²ƒì— ì˜¤ë¥˜ê°€ ë°œìƒí•œë‹¤. ì´ë¥¼ í•´ê²°í•  ë°©ë²•ìœ¼ë¡œ ì••ì¶•íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ì½”ë©ì—ì„œ í•´ì œí•˜ëŠ” ë°©ì‹ì„ ì·¨í•œë‹¤."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_aRq99KUofAn","outputId":"45dabee9-edf5-4b91-c14d-27fa1cd23a91"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive\n","replace val/images/1062037_20211202_5_2_b7_3_2_11_1_0.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "]}],"source":["# ì••ì¶• íŒŒì¼ í•´ì œ - val.zip\n","%cd /content/drive/MyDrive/\n","\n","!unzip -qq \"/content/drive/MyDrive/val.zip\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SoFyXJvDMYQP"},"outputs":[],"source":["# val ë°ì´í„°ì…‹ ë¦¬ìŠ¤íŠ¸ ì •ë¦¬\n","from glob import glob\n","val_img_list = list(glob('/content/drive/MyDrive/val/images/*.jpg'))\n","\n","len(val_img_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xzlP5IJUMEt2"},"outputs":[],"source":["# ì••ì¶• íŒŒì¼ í•´ì œ - train.zip\n","\n","%cd /content/drive/MyDrive/\n","!unzip -qq \"/content/drive/MyDrive/train.zip\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zxAhnN8XOPLY"},"outputs":[],"source":["# train ë°ì´í„°ì…‹ ë¦¬ìŠ¤íŠ¸ ì •ë¦¬\n","train_img_list = list(glob('/content/drive/MyDrive/train/images/*.jpg'))\n","\n","len(train_img_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TU66uayo_-17"},"outputs":[],"source":["with open(\"/content/drive/MyDrive/yolov5/data/dis/train.txt\", \"r\") as f:\n","    train_img_list_2 = f.read()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hPwEVepH9uX8"},"outputs":[],"source":["val_img_list = glob('/content/drive/MyDrive/val/images/*.jpg')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kMmc45Wy5qOF"},"outputs":[],"source":["len(train_img_list_2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HD-4ZNoO933D"},"outputs":[],"source":["len(val_img_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a_UjA9In_j_6"},"outputs":[],"source":["print(len(train_img_list))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Ro-JrDmHdAp"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fXMT1cqtp0sm"},"outputs":[],"source":["import yaml\n","# txt íŒŒì¼ë¡œ ì €ì¥í•œë‹¤ !\n","with open('/content/drive/MyDrive/yolov5/data/dis/train.txt','w') as f:\n","  f.write('\\n'.join(train_img_list) + '\\n')\n","with open('/content/drive/MyDrive/yolov5/data/dis/val.txt','w') as f:\n","  f.write('\\n'.join(val_img_list) + '\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gcm68hPb1oc8"},"outputs":[],"source":["from IPython.core.magic import register_line_cell_magic\n","\n","@register_line_cell_magic\n","def writetemplate(line, cell):\n","  with open(line, 'w') as f:\n","    f.write(cell.format(**globals())) #ì‹¤ì œ ì…€ì˜ í¬ë©§ì—ì„œ íŒŒë¼ë©”í„° ê¸€ë¡œë²Œì„ ê°€ì ¸ì˜¤ê³ \u0003"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"duWivzkH2ixN"},"outputs":[],"source":["%%writetemplate /content/drive/MyDrive/yolov5/data/data.yaml\n","\n","train: /content/drive/MyDrive/train\n","val: /content/drive/MyDrive/val\n","\n","nc: 13\n","names: [\"tenzer\",\"white\",\"N_nope\",\"P_nope\",\"K_nope\",\"calshum_nope\",\"gray_mold\",\"firefurit\",\"mozlalook\",\"noguun\",\"chuck\",\"liilso\",\"namhea\"]\n","     "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3el7jIxw1uvk"},"outputs":[],"source":["# íŒŒì¼ì„ ì—´ì–´ë³¸ë‹¤\n","\n","%cat /content/drive/MyDrive/yolov5/data/data.yaml"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nBh5H5HA114V"},"outputs":[],"source":["# ëª¨ë¸ êµ¬ì„±\n","import yaml\n","\n","with open('/content/drive/MyDrive/yolov5/data/data.yaml', 'r') as stream :\n","  num_classes = str(yaml.safe_load(stream)['nc']) # nc : number classes\n","\n","%cat /content/drive/MyDrive/yolov5/models/yolov5s.yaml"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y4E4G8CR6Q61"},"outputs":[],"source":["%%writetemplate /content/drive/MyDrive/yolov5/models/custom_yolov5s.yaml\n","# nc ê°€ 80ì¸ê²Œ ë„ˆë¬´ í¼ !\n","# nc ê°’ì— ë³€ìˆ˜ë¡œ ì§€ì •í•´ë‘” ê²ƒì„ ì‚¬ìš©\n","\n","# Parameters\n","nc: {num_classes}  # number of classes\n","depth_multiple: 0.33  # model depth multiple\n","width_multiple: 0.50  # layer channel multiple\n","anchors:\n","  - [10,13, 16,30, 33,23]  # P3/8\n","  - [30,61, 62,45, 59,119]  # P4/16\n","  - [116,90, 156,198, 373,326]  # P5/32\n","\n","# YOLOv5 v6.0 backbone\n","backbone:\n","  # [from, number, module, args]\n","  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n","   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n","   [-1, 3, C3, [128]],\n","   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n","   [-1, 6, C3, [256]],\n","   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n","   [-1, 9, C3, [512]],\n","   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n","   [-1, 3, C3, [1024]],\n","   [-1, 1, SPPF, [1024, 5]],  # 9\n","  ]\n","\n","# YOLOv5 v6.0 head\n","head:\n","  [[-1, 1, Conv, [512, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n","   [-1, 3, C3, [512, False]],  # 13\n","\n","   [-1, 1, Conv, [256, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n","   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n","\n","   [-1, 1, Conv, [256, 3, 2]],\n","   [[-1, 14], 1, Concat, [1]],  # cat head P4\n","   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n","\n","   [-1, 1, Conv, [512, 3, 2]],\n","   [[-1, 10], 1, Concat, [1]],  # cat head P5\n","   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n","\n","   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n","  ]  ]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bFvDblcs6U4b"},"outputs":[],"source":["#ì›í•˜ëŠ”ëŒ€ë¡œ ì €ì¥ì´ ëëŠ”ì§€ í™•ì¸\n","%cat /content/drive/MyDrive/yolov5/models/custom_yolov5s.yaml\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AgV_lPZp6XAr"},"outputs":[],"source":["pip install -U albumentations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RLI7npHR6Zmz"},"outputs":[],"source":["class Albumentations:\n","    # YOLOv5 Albumentations class (optional, used if package is installed)\n","    def __init__(self):\n","        self.transform = None\n","        try:\n","            import albumentations as A\n","            check_version(A.__version__, '1.0.3')  # version requirement\n","\n","            self.transform = A.Compose([\n","                A.Blur(blur_limit=50, p=0.1),\n","                A.MedianBlur(blur_limit=51, p=0.1),\n","                A.ToGray(p=0.3)],\n","                bbox_params=A.BboxParams(format='yolo', label_fields=['class_labels']))\n","\n","            logging.info(colorstr('albumentations: ') + ', '.join(f'{x}' for x in self.transform.transforms))\n","        except ImportError:  # package not installed, skip\n","            pass\n","        except Exception as e:\n","            logging.info(colorstr('albumentations: ') + f'{e}')\n","\n","    def __call__(self, im, labels, p=1.0):\n","        if self.transform and random.random() \u003c p:\n","            new = self.transform(image=im, bboxes=labels[:, 1:], class_labels=labels[:, 0])  # transformed\n","            im, labels = new['image'], np.array([[c, *b] for c, b in zip(new['class_labels'], new['bboxes'])])\n","        return im, labels"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":311,"status":"ok","timestamp":1659747795036,"user":{"displayName":"ì„±ë¯¼ì œ","userId":"17141149487272394423"},"user_tz":-540},"id":"d_vZz6zC6dmV"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/yolov5\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/drive/MyDrive/yolov5/yolov5s.pt, cfg=/content/drive/MyDrive/yolov5/models/yolov5s.yaml, data=/content/drive/MyDrive/yolov5/data/data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=50, batch_size=32, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=dis_result, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","remote: Enumerating objects: 11, done.\u001b[K\n","remote: Counting objects: 100% (11/11), done.\u001b[K\n","remote: Compressing objects: 100% (11/11), done.\u001b[K\n","remote: Total 11 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (11/11), done.\n","From https://github.com/ultralytics/yolov5\n","   bc9fcb1..2794483  master     -\u003e origin/master\n","Command 'git fetch origin' timed out after 5 seconds\n","YOLOv5 ğŸš€ v6.1-359-g628c05c Python-3.7.13 torch-1.12.0+cu113 CUDA:0 (Tesla P100-PCIE-16GB, 16281MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mWeights \u0026 Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ğŸš€ runs (RECOMMENDED)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","Overriding model.yaml nc=80 with nc=13\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     48546  models.yolo.Detect                      [13, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","YOLOv5s summary: 270 layers, 7054690 parameters, 7054690 gradients, 16.0 GFLOPs\n","\n","Transferred 342/349 items from /content/drive/MyDrive/yolov5/yolov5s.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","Scaled weight_decay = 0.0005\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 57 weight (no decay), 60 weight, 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/drive/MyDrive/train/labels' images and labels...0 found, 135502 missing, 0 empty, 0 corrupt: 100% 135502/135502 [1:51:23\u003c00:00, 20.27it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mWARNING: No labels found in /content/drive/MyDrive/train/labels.cache. See https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/train/labels.cache\n","Traceback (most recent call last):\n","  File \"train.py\", line 634, in \u003cmodule\u003e\n","    main(opt)\n","  File \"train.py\", line 529, in main\n","    train(opt.hyp, opt, device, callbacks)\n","  File \"train.py\", line 198, in train\n","    shuffle=True)\n","  File \"/content/drive/MyDrive/yolov5/utils/dataloaders.py\", line 131, in create_dataloader\n","    prefix=prefix)\n","  File \"/content/drive/MyDrive/yolov5/utils/dataloaders.py\", line 475, in __init__\n","    assert nf \u003e 0 or not augment, f'{prefix}No labels in {cache_path}. Can not train without labels. See {HELP_URL}'\n","AssertionError: \u001b[34m\u001b[1mtrain: \u001b[0mNo labels in /content/drive/MyDrive/train/labels.cache. Can not train without labels. See https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data\n","CPU times: user 1min 3s, sys: 12.9 s, total: 1min 16s\n","Wall time: 2h 41min 37s\n"]}],"source":["# cache: ë¹ ë¥¸ í•™ìŠµì„ ìœ„í•œ ì´ë¯¸ì§€ ìºì‹œ\n","%%time\n","%cd /content/drive/MyDrive/yolov5\n","!python train.py --img 640 --batch 32 --epochs 50 --data /content/drive/MyDrive/yolov5/data/data.yaml  --cfg /content/drive/MyDrive/yolov5/models/yolov5s.yaml --weights /content/drive/MyDrive/yolov5/yolov5s.pt --name dis_result --cache"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RAl2inqT6wjs"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyM0jr0o+v7M4MF6+EFxy8PS","background_execution":"on","collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1SyHrK4U_bNQLiutCLHl8SgsEyMjB_2ea","name":"Yolov5unpack.ipynb","provenance":[{"file_id":"1Gsnvuzl8HqMwgozouU9t_F50yK7T_nBC","timestamp":1659687684567}],"version":""},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}